{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deerwester.dict        hey.csv                     new_ddoc2.txt\r\n",
      "deerwester2.dict       my_town.ipynb               new_doc2.txt\r\n",
      "deerwester2.mm         my_town2-Copy3.ipynb        prepre.py\r\n",
      "deerwester3.dict       my_town3-Copy1.ipynb        prepre.pyc\r\n",
      "deerwester3.mm         my_town3_todai-Copy1.ipynb  qqq1.csv\r\n",
      "deerwester_todai.dict  my_town3_todai-Copy2.ipynb  qqq2_pesdo.csv\r\n",
      "deerwester_todai.mm    my_town3_todai.ipynb        result.png\r\n",
      "deerwesterr.mm         my_towwn.ipynb              test.txt\r\n",
      "doc2_vec.ipynb         new_answer.csv              todai_pesdo.csv\r\n",
      "experi.txt             new_ccc.csv                 untitled.txt\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 5699)\n",
      "\n",
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "__author__ = 'masatoshi'\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "a=[]\n",
    "\n",
    "with open('hey.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        a.append(row)\n",
    "\n",
    "####print len(a)\n",
    "\n",
    "b=[]\n",
    "for kkk in range(len(a)):\n",
    "    if(len(a[kkk])==1):\n",
    "        b.append(a[kkk][0])\n",
    "\n",
    "###print b[0]\n",
    "\n",
    "from gensim import corpora, models, similarities\n",
    "\n",
    "documents = [\"Human machine interface\",\"a survey of user opinion\",\"graph minors a survery\"]\n",
    "\n",
    "documents = b\n",
    "\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "\n",
    "texts = [[word for word in document.lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "###print texts\n",
    "\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.filter_extremes(no_below=2, no_above=0.3)\n",
    "dictionary.save('/tmp/deerwester.dict')\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "###print corpus\n",
    "\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "corpus_tfidf = tfidf[corpus]\n",
    "answer =[]\n",
    "for doc in corpus_tfidf:\n",
    "    ###print(doc)\n",
    "    answer.append(doc)\n",
    "\n",
    "kkkk = len(dictionary.token2id)\n",
    "###print len(answer)\n",
    "c=[]\n",
    "###print answer[0]\n",
    "for i in answer:\n",
    "    p = np.zeros(kkkk)\n",
    "    for j in i:\n",
    "        p[j[0]] = j[1]\n",
    "    c.append(p)\n",
    "\n",
    "print np.shape(c)\n",
    "print \n",
    "print len(answer[1])\n",
    "###print(dictionary.token2id)\n",
    "\n",
    "train_X = c\n",
    "\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print train_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.21505615184552229, 0.052921379934237879], [0.20422945212479837, 0.027914987518129358], [0.25892551893546345, 0.072101435235729816], [0.20573119563240394, 0.06542110067731477], [0.22151311922451283, -0.019670088069680923], [0.21208524952866081, -0.015566306658592655], [0.24084929257096949, 0.12492761361910854], [0.18457733671168916, 0.10477193185162932], [0.1818774700820367, 0.0020684408040738964], [0.18962196432175565, 0.082134569797680163]]\n"
     ]
    }
   ],
   "source": [
    "lsi = models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=2)\n",
    "corpus_lsi = lsi[corpus_tfidf]\n",
    "hey1 =[]\n",
    "hey2 =[]\n",
    "for i in corpus_lsi:\n",
    "    hey1.append(i[0][1])\n",
    "    hey2.append(i[1][1])                 \n",
    "\n",
    "print hey[0:10]\n",
    "plt.scatter(hey1,hey2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "from collections import OrderedDict\n",
    "rng = np.random.RandomState(1234)\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "###print mnist_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(486, 5699)\n"
     ]
    }
   ],
   "source": [
    "#Autoencoder (or RBM)\n",
    "class Autoencoder:\n",
    "    def __init__(self,visible_dim,hidden_dim,W,function):\n",
    "        ## WRITE ME\n",
    "        self.visible_dim = visible_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.function = function\n",
    "        self.W =W\n",
    "        self.a = theano.shared(np.zeros(visible_dim).astype(np.float32),name=\"a\")\n",
    "        self.b = theano.shared(np.zeros(hidden_dim).astype(np.float32),name=\"b\")\n",
    "        self.params = [self.W,self.a,self.b]\n",
    "\n",
    "    #encoder\n",
    "    def encode(self,x):\n",
    "        ## WRITE ME\n",
    "        u = T.dot(x, self.W)+self.b\n",
    "        y = self.function(u)\n",
    "        return y\n",
    "        \n",
    "    #decoder\n",
    "    def decode(self,x):\n",
    "        ## WRITE ME\n",
    "        u = T.dot(x, self.W.T)+self.a\n",
    "        y = self.function(u)\n",
    "        return y\n",
    "    \n",
    "    #forward propagation\n",
    "    def prop(self,x):\n",
    "        ## WRITE ME\n",
    "        y = self.encode(x)\n",
    "        reconst_x = self.decode(y)\n",
    "        return reconst_x\n",
    "    \n",
    "    #reconstruction error\n",
    "    def reconst_error(self,x,noise):\n",
    "        tilde_x = x*noise\n",
    "        reconst_x = self.prop(tilde_x)\n",
    "        error = T.mean(T.sum(T.nnet.binary_crossentropy(reconst_x,x),axis=1))\n",
    "        return error, reconst_x\n",
    "    \n",
    "#SGD\n",
    "def sgd(params,gparams,lr=0.1):\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "  \n",
    "\n",
    "#Multi Layer Perceptron\n",
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function):\n",
    "        self.W = theano.shared(rng.uniform(low=-np.sqrt(6. / (in_dim + out_dim)),high =np.sqrt(6. / (in_dim + out_dim)),size =(in_dim,out_dim)).astype('float32'), name = 'W')\n",
    "        self.b = theano.shared(np.zeros(out_dim).astype('float32'), name = 'bias')\n",
    "        self.params = [ self.W, self.b]\n",
    "        \n",
    "        self.W1 = theano.shared(0*rng.uniform(low=-np.sqrt(6. / (in_dim + out_dim)),high =np.sqrt(6. / (in_dim + out_dim)),size =(in_dim,out_dim)).astype('float32'), name = 'W')\n",
    "        self.b1 = theano.shared(np.zeros(out_dim).astype('float32'), name = 'bias')\n",
    "        self.momentums = [ self.W1, self.b1]       \n",
    "             \n",
    "        self.function = function\n",
    "        self.h = None\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim =out_dim\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h=self.function(theano.tensor.dot(x,self.W)+self.b)\n",
    "        self.h = h\n",
    "        return h\n",
    "    \n",
    "    def set_pretraining(self):\n",
    "        ae = Autoencoder(self.in_dim,self.out_dim,self.W,self.function)\n",
    "        ###noise = T.matrix('noise')\n",
    "        ###noise =rng.binomial(size=train_X[start:end].shape, n=1, p=1-corruption_level)\n",
    "        ##start = i*batch_size\n",
    "        ##end = (i+1)*batch_size\n",
    "        self.params[0] =ae.params[0]\n",
    "        x  = T.matrix('X')\n",
    "        noise = T.matrix('noise')\n",
    "        ###noise =rng.binomial(size=x.shape, n=1, p=1-corruption_level)\n",
    "        cost,reconst_x = ae.reconst_error(x,noise)\n",
    "        params  = ae.params\n",
    "        gparams = T.grad(cost, params)\n",
    "        updates = sgd(params,gparams)\n",
    "        self.pretraining = theano.function([x,noise], [cost,reconst_x], updates=updates, allow_input_downcast=True)\n",
    "        hidden = ae.encode(x)\n",
    "        self.encode_function = theano.function([x], hidden, allow_input_downcast=True)\n",
    "#Pre-training\n",
    "X = np.array(train_X)\n",
    "print X.shape\n",
    "\n",
    "def fff(x):\n",
    "    return x\n",
    "\n",
    "layers = [Layer(X.shape[1],2,T.nnet.sigmoid)]\n",
    "\n",
    "def sgd(params,gparams,lr=0.1):\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:0, Error:795.136108\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:1, Error:176.416855\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:2, Error:118.711349\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:3, Error:96.387024\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:4, Error:84.717323\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:5, Error:77.629997\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:6, Error:72.921722\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:7, Error:69.596863\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:8, Error:67.150322\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:9, Error:65.278595\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:10, Error:63.814487\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:11, Error:62.642971\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:12, Error:61.686920\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:13, Error:60.899193\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:14, Error:60.238403\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:15, Error:59.679440\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:16, Error:59.202190\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:17, Error:58.792225\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:18, Error:58.433777\n",
      "(5, 5699)\n",
      "Pre-training:: layer:0, Epoch:19, Error:58.122734\n"
     ]
    }
   ],
   "source": [
    "for l, layer in enumerate(layers):\n",
    "    corruption_level = 0.02## WRITE ME\n",
    "    batch_size = 5\n",
    "    X = shuffle(X)\n",
    "    nbatches = X.shape[0] // batch_size\n",
    "    ###print X.shape\n",
    "    ###print nbatches       \n",
    "    layer.set_pretraining()\n",
    "    for epoch in range(20):\n",
    "        err_all = []\n",
    "        reconst_all =[]\n",
    "        for i in range(nbatches):\n",
    "            start = i*batch_size\n",
    "            end = (i+1)*batch_size\n",
    "            noise =rng.binomial(size=X[start:end].shape, n=1, p=1-corruption_level)\n",
    "            err,recosnt = layer.pretraining(X[start:end],noise)\n",
    "            err_all.append(err)\n",
    "            reconst_all.append(recosnt)\n",
    "        print reconst_all[0].shape\n",
    "        print \"Pre-training:: layer:%d, Epoch:%d, Error:%lf\" %(l,epoch, np.mean(err_all))\n",
    "    X = layer.encode_function(X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5699)\n",
      "(486, 2)\n",
      "[ 0.9980008   0.99800867]\n",
      "[[ 0.99999046  0.99999058]\n",
      " [ 1.          0.99999964]\n",
      " [ 0.99876392  0.99876744]\n",
      " [ 0.99908757  0.99907684]\n",
      " [ 0.9997772   0.99977058]\n",
      " [ 0.99942654  0.9994536 ]\n",
      " [ 1.          1.        ]\n",
      " [ 0.99998713  0.99998701]\n",
      " [ 0.9987852   0.99878186]]\n"
     ]
    }
   ],
   "source": [
    "#train_size = len(train_data)\n",
    "print reconst_all[0].shape\n",
    "print X.shape\n",
    "print X[0]\n",
    "print X[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "#test_X  , test_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [self.W]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = self.W[x]\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, func,scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.h = None\n",
    "        self.params = [ self.W, self.b ]\n",
    "        self.func = func\n",
    "    def fprop(self, x):\n",
    "        c = T.dot(x, self.W)+self.b\n",
    "        h = self.func(c)\n",
    "        self.h = h\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, in_dim, hid_dim, func,scale=0.05):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "        self.func = func\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(hid_dim,hid_dim ) * scale)\n",
    "        self.Wh = sharedX(rng.randn(in_dim,hid_dim) * scale)\n",
    "        self.bh = sharedX(rng.randn(hid_dim) * scale)\n",
    "        ###self.Wy = sharedX(rng.randn(hid_dim,out_dim ) * scale)\n",
    "        ###self.by = sharedX(rng.randn(out_dim ) * scale)\n",
    "        \n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(rng.randn(hid_dim) * scale)\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [self.Wh,self.bh,self.Wx]\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = self.func(T.dot(h_tm1,self.Wx)+T.dot(u_t,self.Wh)+self.bh)\n",
    "            ###self.output_info.append(h)\n",
    "            return h\n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(fn=step,sequences=x, outputs_info=self.h0)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        #WRITE ME\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "print vocab_size\n",
    "hid_dim    = 150\n",
    "out_dim    = len(tag2index)\n",
    "in_dim = 400\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")        \n",
    "layers =[Projection(vocab_size,in_dim),RNN(in_dim,hid_dim,T.tanh),Linear(hid_dim,out_dim,T.nnet.softmax)]\n",
    "\n",
    "\n",
    "train_X_pesdo =[i[::-1] for i in train_X]\n",
    "train_y_pesdo =[i[::-1] for i in train_y]\n",
    "\n",
    "                                     \n",
    "###layer =[Projection(in_dim,vocab_size),]\n",
    "prob = prop(layers, x) \n",
    "\n",
    "cost = - T.mean((T.log(prob))[T.arange(x.shape[0]), t])# Loss function を決める　 prop\n",
    "pred =  T.argmax(prob, axis=1)\n",
    "##予測した確率から、予測値を決める T.mean\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "updates2 = sgd(cost, params, lr=numpy.float32(0.001))\n",
    "updates3 = sgd(cost, params, lr=numpy.float32(0.0001))\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "train2 = theano.function([x,t], cost, updates=updates2)\n",
    "train3 = theano.function([x,t], cost, updates=updates3)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "#test  = theano.function([x]　,　pred)\n",
    "\n",
    "epochs = 8\n",
    "## Train\n",
    "\n",
    "train_X = train_X + train_X_pesdo\n",
    "train_y = train_y + train_y_pesdo\n",
    "for epoch in range(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        if(epoch<=3):\n",
    "            cost = train(instance_x, instance_y)\n",
    "        elif(4<=epoch<=6):\n",
    "            cost = train2(instance_x, instance_y)\n",
    "        else:\n",
    "            cost = train3(instance_x, instance_y)\n",
    "        ###print cost\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost)\n",
    "    \n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(test_X, test_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        pred_y += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y\n",
    "        dev_cost.append(cost)\n",
    "    ###print dev_cost\n",
    "    print classification_report(dev_true,pred_y)            \n",
    "   \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
