{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan\n",
    "\n",
    "Theano ではループのために For 文ではなく、Scan というものを使います　　\n",
    "少しややこしいので、簡単な例を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   4.   9.  16.  25.]\n"
     ]
    }
   ],
   "source": [
    "##Suppose you have a sequence [1, 2, 3, 4, 5] let's define identity function with scan\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x):\n",
    "    return x*x\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=None\n",
    "                    )\n",
    "### fn は毎回使う関数\n",
    "### sequences　は毎回使うxのこと\n",
    "### output_info は初期値\n",
    "\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  3.   5.   8.  12.  17.]\n"
     ]
    }
   ],
   "source": [
    "##Next we define accumulation function\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=2.0, #Initial value for h\n",
    "                       #go_backwards=True #you might use it for bi-directional RNNs\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.]\n",
      " [  2.   4.   6.   8.  10.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Let's do the same thing with matrix, accumulation over column\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=numpy.array([0., 0., 0., 0., 0.]) #Initial value for h, it's better to use T.alloc().\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Advanced :: take previous inputs\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1, h_tm2):\n",
    "    return x + h_tm1 + h_tm2\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=[ dict(input= x, taps = [0, -1, -2])],\n",
    "                       outputs_info=None #Initial value for h\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5],[1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [宿題] POS Tagging\n",
    "\n",
    "文が与えられた時、その品詞を予測する RNN を学習します。\n",
    "\n",
    "word2index は単語をIDに変換する辞書、tag2index は品詞をIDに変換する辞書です。  \n",
    "train_data, dev_data には文と品詞タグのペアが入っています。  \n",
    "文の長さと品詞タグの長さは必ず同じです。\n",
    "\n",
    "encode_dataset を使うと単語と品詞をIDに変換することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GRID K520\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def load_data(file_path):\n",
    "    dataset = []\n",
    "    vocab, tag = set(), set()\n",
    "    for line in open(file_path):\n",
    "        instance = [ l.strip().split() for l in line.split('|||') ]\n",
    "        vocab.update(instance[0])\n",
    "        tag.update(instance[1])\n",
    "        dataset.append(instance)\n",
    "    return dataset, vocab, tag\n",
    "\n",
    "def encode_dataset(dataset, word2index, tag2index):\n",
    "    X, y = [], []\n",
    "    vocab = set(word2index.keys())\n",
    "    for sentence, tags in dataset:\n",
    "        X.append([ word2index[word] if word in vocab else word2index['<unk>'] for word in sentence])\n",
    "        y.append([ tag2index[tag] for tag in tags])\n",
    "    return X, y\n",
    "\n",
    "train_data, train_vocab, train_tags = load_data('train.unk')\n",
    "special_words = set(['<unk>'])\n",
    "\n",
    "word2index = dict(map(lambda x: (x[1], x[0]), enumerate(train_vocab | special_words)))\n",
    "tag2index  = dict(map(lambda x: (x[1], x[0]), enumerate(train_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "###print train_data[0]\n",
    "###print word2index\n",
    "###print tag2index\n",
    "\n",
    "train_data, dev_data = train_data[:2000], train_data[2000:2100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In', 'an', 'Oct.', '19', 'review', 'of', '``', 'The', 'Misanthrope', \"''\", 'at', 'Chicago', \"'s\", 'Goodman', 'Theatre', '``', 'Revitalized', 'Classics', 'Take', 'the', 'Stage', 'in', 'Windy', 'City', ',', \"''\", 'Leisure', '&', 'Arts', ',', 'the', 'role', 'of', 'Celimene', ',', 'played', 'by', 'Kim', 'Cattrall', ',', 'was', 'mistakenly', 'attributed', 'to', 'Christina', 'Haag', '.']\n",
      "['IN', 'DT', 'NNP', 'CD', 'NN', 'IN', '``', 'DT', 'NN', \"''\", 'IN', 'NNP', 'POS', 'NNP', 'NNP', '``', 'VBN', 'NNS', 'VBP', 'DT', 'NN', 'IN', 'NNP', 'NNP', ',', \"''\", 'NN', 'CC', 'NNS', ',', 'DT', 'NN', 'IN', 'NNP', ',', 'VBN', 'IN', 'NNP', 'NNP', ',', 'VBD', 'RB', 'VBN', 'TO', 'NNP', 'NNP', '.']\n",
      "[36601, 10330, 1934, 24227, 36489, 17415, 9885, 13071, 18383, 19160, 10335, 257, 19170, 25434, 16956, 9885, 23272, 30009, 3488, 12011, 26700, 14331, 23198, 37214, 33153, 19160, 37187, 18143, 37598, 33153, 12011, 584, 17415, 24050, 33153, 28607, 10880, 24817, 7739, 33153, 21511, 34465, 16049, 6994, 28274, 34462, 385]\n",
      "[34, 11, 24, 32, 15, 34, 25, 11, 15, 5, 34, 24, 17, 24, 24, 25, 7, 23, 6, 11, 15, 34, 24, 24, 4, 5, 15, 27, 23, 4, 11, 15, 34, 24, 4, 7, 34, 24, 24, 4, 2, 21, 7, 19, 24, 24, 18]\n",
      "2000\n",
      "2000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print train_data[0][0]\n",
    "print train_data[0][1]\n",
    "\n",
    "print encode_dataset(train_data, word2index, tag2index)[0][0]\n",
    "print encode_dataset(train_data, word2index, tag2index)[1][0]\n",
    "print len(encode_dataset(train_data, word2index, tag2index)[0])\n",
    "print len(encode_dataset(train_data, word2index, tag2index)[1])\n",
    "print len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In IN\n",
      "an DT\n",
      "Oct. NNP\n",
      "19 CD\n",
      "review NN\n",
      "of IN\n",
      "`` ``\n",
      "The DT\n",
      "Misanthrope NN\n",
      "'' ''\n",
      "at IN\n",
      "Chicago NNP\n",
      "'s POS\n",
      "Goodman NNP\n",
      "Theatre NNP\n",
      "`` ``\n",
      "Revitalized VBN\n",
      "Classics NNS\n",
      "Take VBP\n",
      "the DT\n",
      "Stage NN\n",
      "in IN\n",
      "Windy NNP\n",
      "City NNP\n",
      ", ,\n",
      "'' ''\n",
      "Leisure NN\n",
      "& CC\n",
      "Arts NNS\n",
      ", ,\n",
      "the DT\n",
      "role NN\n",
      "of IN\n",
      "Celimene NNP\n",
      ", ,\n",
      "played VBN\n",
      "by IN\n",
      "Kim NNP\n",
      "Cattrall NNP\n",
      ", ,\n",
      "was VBD\n",
      "mistakenly RB\n",
      "attributed VBN\n",
      "to TO\n",
      "Christina NNP\n",
      "Haag NNP\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "for word, tag in zip(train_data[0][0], train_data[0][1]):\n",
    "    print word, tag\n",
    "    \n",
    "test_X  , test_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを完成させて提出してください　　\n",
    "\n",
    "今回の入力は単語のID列（ベクトル x）と品詞のID列 (ベクトル y)です。  \n",
    "Projection レイヤーを使って、単語をベクトルに変換します。  \n",
    "その後、RNN に入力し、その出力値をSotfmax関数を使って確率分布に変換します。  \n",
    "予測は画像の時とおなじく、最大の確率を持つクラスを予測とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38055\n",
      "EPOCH:: 1, Iteration 0, cost: 7.530\n",
      "EPOCH:: 1, Iteration 1000, cost: 1.100\n",
      "EPOCH:: 1, Iteration 2000, cost: 1.228\n",
      "EPOCH:: 1, Iteration 3000, cost: 1.439\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "###test_X  , test_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [self.W]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = self.W[x]\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, func,scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.h = None\n",
    "        self.params = [ self.W, self.b ]\n",
    "        self.func = func\n",
    "    def fprop(self, x):\n",
    "        c = T.dot(x, self.W)+self.b\n",
    "        h = self.func(c)\n",
    "        self.h = h\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, in_dim, hid_dim, func,scale=0.05):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "        self.func = func\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(hid_dim,hid_dim ) * scale)\n",
    "        self.Wh = sharedX(rng.randn(in_dim,hid_dim) * scale)\n",
    "        self.bh = sharedX(rng.randn(hid_dim) * scale)\n",
    "        ###self.Wy = sharedX(rng.randn(hid_dim,out_dim ) * scale)\n",
    "        ###self.by = sharedX(rng.randn(out_dim ) * scale)\n",
    "        \n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(rng.randn(hid_dim) * scale)\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [self.Wh,self.bh,self.Wx]\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = self.func(T.dot(h_tm1,self.Wx)+T.dot(u_t,self.Wh)+self.bh)\n",
    "            ###self.output_info.append(h)\n",
    "            return h\n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(fn=step,sequences=x, outputs_info=self.h0)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        #WRITE ME\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "print vocab_size\n",
    "hid_dim    = 150\n",
    "out_dim    = len(tag2index)\n",
    "in_dim = 400\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")        \n",
    "layers =[Projection(vocab_size,in_dim),RNN(in_dim,hid_dim,T.tanh),Linear(hid_dim,out_dim,T.nnet.softmax)]\n",
    "\n",
    "\n",
    "train_X_pesdo =[i[::-1] for i in train_X]\n",
    "train_y_pesdo =[i[::-1] for i in train_y]\n",
    "\n",
    "                                     \n",
    "###layer =[Projection(in_dim,vocab_size),]\n",
    "prob = prop(layers, x) \n",
    "\n",
    "cost = - T.mean((T.log(prob))[T.arange(x.shape[0]), t])# Loss function を決める　 prop\n",
    "pred =  T.argmax(prob, axis=1)\n",
    "##予測した確率から、予測値を決める T.mean\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "updates2 = sgd(cost, params, lr=numpy.float32(0.001))\n",
    "updates3 = sgd(cost, params, lr=numpy.float32(0.0001))\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "train2 = theano.function([x,t], cost, updates=updates2)\n",
    "train3 = theano.function([x,t], cost, updates=updates3)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "test  = theano.function([x],pred)\n",
    "\n",
    "epochs = 10\n",
    "## Train\n",
    "\n",
    "train_X = train_X + train_X_pesdo\n",
    "train_y = train_y + train_y_pesdo\n",
    "for epoch in range(1):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        if(epoch<=3):\n",
    "            cost = train(instance_x, instance_y)\n",
    "        elif(4<=epoch<=7):\n",
    "            cost = train2(instance_x, instance_y)\n",
    "        else:\n",
    "            cost = train3(instance_x, instance_y)\n",
    "        ###print cost\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost)\n",
    "    '''\n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(test_X, test_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        pred_y += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y\n",
    "        dev_cost.append(cost)\n",
    "    ###print dev_cost\n",
    "    print classification_report(dev_true,pred_y)            \n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    pred_y =[]\n",
    "    for i, instance_x in enumerate(test_X):\n",
    "        pred = test(instance_x)\n",
    "        pred_y = pred_y + list(pred) # 予測結果はベクトル\n",
    "\n",
    "    a=[]\n",
    "    for i in test_y:z\n",
    "        a+=i\n",
    "    print classification_report(a,pred_y)  \n",
    "    '''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38055\n",
      "EPOCH:: 1, Iteration 0, cost: 8.075\n",
      "EPOCH:: 1, Iteration 1000, cost: 1.384\n",
      "EPOCH:: 1, Iteration 2000, cost: 1.106\n",
      "EPOCH:: 1, Iteration 3000, cost: 0.846\n",
      "EPOCH:: 2, Iteration 0, cost: 0.474\n",
      "EPOCH:: 2, Iteration 1000, cost: 1.464\n",
      "EPOCH:: 2, Iteration 2000, cost: 0.302\n",
      "EPOCH:: 2, Iteration 3000, cost: 0.088\n",
      "EPOCH:: 3, Iteration 0, cost: 0.035\n",
      "EPOCH:: 3, Iteration 1000, cost: 0.437\n",
      "EPOCH:: 3, Iteration 2000, cost: 1.019\n",
      "EPOCH:: 3, Iteration 3000, cost: 0.227\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "###test_X  , test_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [self.W]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = self.W[x]\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, func,scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.h = None\n",
    "        self.params = [ self.W, self.b ]\n",
    "        self.func = func\n",
    "    def fprop(self, x):\n",
    "        c = T.dot(x, self.W)+self.b\n",
    "        h = self.func(c)\n",
    "        self.h = h\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, in_dim, hid_dim, func,scale=0.05):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "        self.func = func\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(hid_dim,hid_dim ) * scale)\n",
    "        self.Wh = sharedX(rng.randn(in_dim,hid_dim) * scale)\n",
    "        self.bh = sharedX(rng.randn(hid_dim) * scale)\n",
    "        ###self.Wy = sharedX(rng.randn(hid_dim,out_dim ) * scale)\n",
    "        ###self.by = sharedX(rng.randn(out_dim ) * scale)\n",
    "        \n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(rng.randn(hid_dim) * scale)\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [self.Wh,self.bh,self.Wx]\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = self.func(T.dot(h_tm1,self.Wx)+T.dot(u_t,self.Wh)+self.bh)\n",
    "            ###self.output_info.append(h)\n",
    "            return h\n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(fn=step,sequences=x, outputs_info=self.h0)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        #WRITE ME\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "print vocab_size\n",
    "hid_dim    = 150\n",
    "out_dim    = len(tag2index)\n",
    "in_dim = 400\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")        \n",
    "layers =[Projection(vocab_size,in_dim),RNN(in_dim,hid_dim,T.tanh),Linear(hid_dim,out_dim,T.nnet.softmax)]\n",
    "\n",
    "\n",
    "train_X_pesdo =[i[::-1] for i in train_X]\n",
    "train_y_pesdo =[i[::-1] for i in train_y]\n",
    "\n",
    "                                     \n",
    "###layer =[Projection(in_dim,vocab_size),]\n",
    "prob = prop(layers, x) \n",
    "\n",
    "cost = - T.mean((T.log(prob))[T.arange(x.shape[0]), t])# Loss function を決める　 prop\n",
    "pred =  T.argmax(prob, axis=1)\n",
    "##予測した確率から、予測値を決める T.mean\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "updates2 = sgd(cost, params, lr=numpy.float32(0.001))\n",
    "updates3 = sgd(cost, params, lr=numpy.float32(0.0001))\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "train2 = theano.function([x,t], cost, updates=updates2)\n",
    "train3 = theano.function([x,t], cost, updates=updates3)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "test  = theano.function([x],pred)\n",
    "\n",
    "epochs = 3\n",
    "## Train\n",
    "\n",
    "train_X = train_X + train_X_pesdo\n",
    "train_y = train_y + train_y_pesdo\n",
    "for epoch in range(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        if(epoch<=2):\n",
    "            cost = train(instance_x, instance_y)\n",
    "        elif(3<=epoch<=4):\n",
    "            cost = train2(instance_x, instance_y)\n",
    "        else:\n",
    "            cost = train3(instance_x, instance_y)\n",
    "        ###print cost\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost)\n",
    "    '''\n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(test_X, test_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        pred_y += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y\n",
    "        dev_cost.append(cost)\n",
    "    ###print dev_cost\n",
    "    print classification_report(dev_true,pred_y)            \n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    pred_y =[]\n",
    "    for i, instance_x in enumerate(test_X):\n",
    "        pred = test(instance_x)\n",
    "        pred_y = pred_y + list(pred) # 予測結果はベクトル\n",
    "    print classification_report(dev_true,pred_y)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.768532088877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#test_data,  test_vocab, test_tags = load_data('test.unk')\n",
    "###test_X , test_y  = encode_dataset(test_data,  word2index, tag2index)\n",
    "\n",
    "test_true, test_pred = [], []\n",
    "for i, (instance_x, instance_y) in enumerate(zip(test_X, test_y)):\n",
    "    test_pred += list(test(instance_x))\n",
    "    test_true += instance_y\n",
    "        \n",
    "print f1_score(test_true, test_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        25\n",
      "          1       0.48      0.38      0.42        37\n",
      "          2       0.87      0.75      0.80       102\n",
      "          3       0.75      0.89      0.81        63\n",
      "          4       1.00      1.00      1.00       118\n",
      "          5       1.00      1.00      1.00        17\n",
      "          6       0.93      0.50      0.65        26\n",
      "          7       0.62      0.62      0.62        45\n",
      "          8       0.66      0.61      0.63       195\n",
      "          9       1.00      0.67      0.80         6\n",
      "         10       0.79      0.70      0.74        43\n",
      "         11       0.98      0.99      0.99       264\n",
      "         13       0.80      1.00      0.89         4\n",
      "         14       1.00      1.00      1.00        14\n",
      "         15       0.70      0.84      0.76       377\n",
      "         17       1.00      1.00      1.00        23\n",
      "         18       1.00      1.00      1.00        99\n",
      "         19       1.00      1.00      1.00        49\n",
      "         20       0.98      1.00      0.99        43\n",
      "         21       0.68      0.72      0.70        80\n",
      "         22       1.00      1.00      1.00        10\n",
      "         23       0.80      0.76      0.78       184\n",
      "         24       0.77      0.71      0.74       269\n",
      "         25       1.00      1.00      1.00        10\n",
      "         26       0.75      1.00      0.86         6\n",
      "         27       1.00      1.00      1.00        59\n",
      "         29       0.00      0.00      0.00         3\n",
      "         30       0.00      0.00      0.00         0\n",
      "         31       0.43      0.60      0.50         5\n",
      "         32       0.85      0.67      0.75        90\n",
      "         33       1.00      1.00      1.00         3\n",
      "         34       0.96      0.95      0.96       300\n",
      "         35       1.00      1.00      1.00         1\n",
      "         36       0.97      1.00      0.98        32\n",
      "         37       0.00      0.00      0.00         0\n",
      "         38       1.00      0.80      0.89         5\n",
      "         39       0.78      0.70      0.74        10\n",
      "         42       0.62      0.83      0.71         6\n",
      "\n",
      "avg / total       0.84      0.83      0.83      2623\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/home/ubuntu/venv/local/lib/python2.7/site-packages/sklearn/metrics/classification.py:1076: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "a=[]\n",
    "for i in test_y:\n",
    "    a+=i\n",
    "print classification_report(a,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38055\n",
      "EPOCH:: 1, Iteration 0, cost: 7.374\n",
      "EPOCH:: 1, Iteration 1000, cost: 1.366\n",
      "EPOCH:: 1, Iteration 2000, cost: 0.971\n",
      "EPOCH:: 1, Iteration 3000, cost: 1.260\n",
      "EPOCH:: 2, Iteration 0, cost: 0.492\n",
      "EPOCH:: 2, Iteration 1000, cost: 0.967\n",
      "EPOCH:: 2, Iteration 2000, cost: 0.871\n",
      "EPOCH:: 2, Iteration 3000, cost: 1.205\n",
      "EPOCH:: 3, Iteration 0, cost: 1.014\n",
      "EPOCH:: 3, Iteration 1000, cost: 0.521\n",
      "EPOCH:: 3, Iteration 2000, cost: 0.932\n",
      "EPOCH:: 3, Iteration 3000, cost: 0.470\n",
      "EPOCH:: 4, Iteration 0, cost: 0.320\n",
      "EPOCH:: 4, Iteration 1000, cost: 0.490\n",
      "EPOCH:: 4, Iteration 2000, cost: 0.829\n",
      "EPOCH:: 4, Iteration 3000, cost: 0.304\n",
      "EPOCH:: 5, Iteration 0, cost: 0.209\n",
      "EPOCH:: 5, Iteration 1000, cost: 0.176\n",
      "EPOCH:: 5, Iteration 2000, cost: 0.172\n",
      "EPOCH:: 5, Iteration 3000, cost: 0.673\n",
      "EPOCH:: 6, Iteration 0, cost: 0.635\n",
      "EPOCH:: 6, Iteration 1000, cost: 0.356\n",
      "EPOCH:: 6, Iteration 2000, cost: 0.066\n",
      "EPOCH:: 6, Iteration 3000, cost: 0.542\n",
      "EPOCH:: 7, Iteration 0, cost: 0.148\n",
      "EPOCH:: 7, Iteration 1000, cost: 0.294\n",
      "EPOCH:: 7, Iteration 2000, cost: 0.273\n",
      "EPOCH:: 7, Iteration 3000, cost: 0.180\n",
      "EPOCH:: 8, Iteration 0, cost: 0.420\n",
      "EPOCH:: 8, Iteration 1000, cost: 0.360\n",
      "EPOCH:: 8, Iteration 2000, cost: 0.472\n",
      "EPOCH:: 8, Iteration 3000, cost: 0.439\n",
      "EPOCH:: 9, Iteration 0, cost: 0.143\n",
      "EPOCH:: 9, Iteration 1000, cost: 0.122\n",
      "EPOCH:: 9, Iteration 2000, cost: 0.714\n",
      "EPOCH:: 9, Iteration 3000, cost: 0.155\n",
      "EPOCH:: 10, Iteration 0, cost: 0.237\n",
      "EPOCH:: 10, Iteration 1000, cost: 0.240\n",
      "EPOCH:: 10, Iteration 2000, cost: 0.427\n",
      "EPOCH:: 10, Iteration 3000, cost: 0.324\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "###test_X  , test_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [self.W]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = self.W[x]\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, func,scale=0.5):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.h = None\n",
    "        self.params = [ self.W, self.b ]\n",
    "        self.func = func\n",
    "    def fprop(self, x):\n",
    "        c = T.dot(x, self.W)+self.b\n",
    "        h = self.func(c)\n",
    "        self.h = h\n",
    "        return h\n",
    "\n",
    "\n",
    "\n",
    "class RNN:\n",
    "    def __init__(self, in_dim, hid_dim, func,scale=0.05):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "        self.func = func\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(hid_dim,hid_dim ) * scale)\n",
    "        self.Wh = sharedX(rng.randn(in_dim,hid_dim) * scale)\n",
    "        self.bh = sharedX(rng.randn(hid_dim) * scale)\n",
    "        ###self.Wy = sharedX(rng.randn(hid_dim,out_dim ) * scale)\n",
    "        ###self.by = sharedX(rng.randn(out_dim ) * scale)\n",
    "        \n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(rng.randn(hid_dim) * scale)\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [self.Wh,self.bh,self.Wx]\n",
    "    \n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = self.func(T.dot(h_tm1,self.Wx)+T.dot(u_t,self.Wh)+self.bh)\n",
    "            ###self.output_info.append(h)\n",
    "            return h\n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(fn=step,sequences=x, outputs_info=self.h0)\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        #WRITE ME\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "print vocab_size\n",
    "hid_dim    = 150\n",
    "out_dim    = len(tag2index)\n",
    "in_dim = 400\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")        \n",
    "layers =[Projection(vocab_size,in_dim),RNN(in_dim,hid_dim,T.tanh),Linear(hid_dim,out_dim,T.nnet.softmax)]\n",
    "\n",
    "\n",
    "train_X_pesdo =[i[::-1] for i in train_X]\n",
    "train_y_pesdo =[i[::-1] for i in train_y]\n",
    "\n",
    "                                     \n",
    "###layer =[Projection(in_dim,vocab_size),]\n",
    "prob = prop(layers, x) \n",
    "\n",
    "cost = - T.mean((T.log(prob))[T.arange(x.shape[0]), t])# Loss function を決める　 prop\n",
    "pred =  T.argmax(prob, axis=1)\n",
    "##予測した確率から、予測値を決める T.mean\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "updates2 = sgd(cost, params, lr=numpy.float32(0.001))\n",
    "updates3 = sgd(cost, params, lr=numpy.float32(0.0001))\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "train2 = theano.function([x,t], cost, updates=updates2)\n",
    "train3 = theano.function([x,t], cost, updates=updates3)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "test  = theano.function([x],pred)\n",
    "\n",
    "epochs = 10\n",
    "## Train\n",
    "\n",
    "train_X = train_X + train_X_pesdo\n",
    "train_y = train_y + train_y_pesdo\n",
    "for epoch in range(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        if(epoch<=3):\n",
    "            cost = train(instance_x, instance_y)\n",
    "        elif(4<=epoch<=7):\n",
    "            cost = train2(instance_x, instance_y)\n",
    "        else:\n",
    "            cost = train3(instance_x, instance_y)\n",
    "        ###print cost\n",
    "        if i % 1000 == 0:\n",
    "            print \"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost)\n",
    "    '''\n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(test_X, test_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        pred_y += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y\n",
    "        dev_cost.append(cost)\n",
    "    ###print dev_cost\n",
    "    print classification_report(dev_true,pred_y)            \n",
    "    dev_true, pred_y = [], []\n",
    "    dev_cost = []\n",
    "    '''\n",
    "    pred_y =[]\n",
    "    for i, instance_x in enumerate(test_X):\n",
    "        pred = test(instance_x)\n",
    "        pred_y = pred_y + list(pred) # 予測結果はベクトル\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
